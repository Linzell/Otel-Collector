receivers:
  otlp:
    protocols:
      grpc:
        max_recv_msg_size_mib: 4
        endpoint: 0.0.0.0:4317
        tls:
          insecure: true
      http:
        endpoint: 0.0.0.0:4318
        tls:
          insecure: true

processors:
  batch:
    send_batch_size: 10000
    timeout: 200ms

exporters:
  debug:
    verbosity: detailed

  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      label1: value1

  logging:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200

  zipkin:
    endpoint: "http://valiant-enjoyment.railway.internal:9411/api/v2/spans"
    format: proto

  otlp/jaeger:
    endpoint: overflowing-acceptance.railway.internal:4317
    tls:
      insecure: true
    timeout: 30s
    sending_queue:
      enabled: true
      num_consumers: 10
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

extensions:
  health_check:
    endpoint: :13133
  pprof:
    endpoint: :1888
  zpages:
    endpoint: :55679

service:
  extensions: [pprof, zpages, health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, zipkin, otlp/jaeger, debug]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, prometheus, debug]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, debug]

telemetry:
  logs:
    level: "debug"
